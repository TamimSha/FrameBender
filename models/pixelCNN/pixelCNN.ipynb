{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('tensor': conda)",
   "display_name": "Python 3.8.5 64-bit ('tensor': conda)",
   "metadata": {
    "interpreter": {
     "hash": "702e536130de1e86921bfab1dd82b30c849ef606fa2b1b0087ff19762b2772f0"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv1D, MaxPooling2D, Dropout, Conv2DTranspose\n",
    "from tensorflow.keras.layers import UpSampling2D, add, Cropping2D, ReLU, BatchNormalization, Lambda, PReLU\n",
    "from tensorflow.keras.layers import Concatenate, Reshape, MaxPooling1D, Cropping1D, ZeroPadding1D, Flatten\n",
    "from tensorflow.keras.layers import AveragePooling2D, LSTM, RepeatVector, TimeDistributed, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU, Layer, Activation, multiply\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence, OrderedEnqueuer\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras import activations, layers\n",
    "from tensorflow.keras.backend import expand_dims, mean, clip, set_image_data_format\n",
    "\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "from scipy import ndimage, misc\n",
    "from skimage.transform import resize, rescale\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(devices[0], True)\n",
    "#tf.keras.backend.set_floatx('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedCNN(object):\n",
    "    ''' Convolution layer with gated activation unit. '''\n",
    "\n",
    "    def __init__(self, nb_filters, stack_name, v_map=None, h=None, crop_right=False, **kwargs):\n",
    "        '''\n",
    "        Args:\n",
    "            nb_filters (int)         : Number of the filters (feature maps)\n",
    "            stack_name (str)\t\t: 'vertical' or 'horizontal'\n",
    "            v_map (numpy.ndarray)   : Vertical maps if feeding into horizontal stack. (default:None)\n",
    "            h (numpy.ndarray)       : Latent vector to model the conditional distribution p(x|h) (default:None)\n",
    "            crop_right (bool)       : if True, crop rightmost of the feature maps (mask A, introduced in [https://arxiv.org/abs/1601.06759] )\n",
    "        '''\n",
    "        self.nb_filters = nb_filters\n",
    "        self.stack_name = stack_name\n",
    "        self.v_map = v_map\n",
    "        self.h = h\n",
    "        self.crop_right = crop_right\n",
    "\n",
    "    @staticmethod\n",
    "    def _crop_right(x):\n",
    "        x_shape = K.int_shape(x)\n",
    "        return x[:,:,:x_shape[2]-1,:]\n",
    "\n",
    "    def __call__(self, xW, layer_idx):\n",
    "        '''calculate gated activation maps given input maps '''\n",
    "        if self.stack_name == 'vertical':\n",
    "            stack_tag = 'v'\n",
    "        elif self.stack_name == 'horizontal':\n",
    "            stack_tag = 'h'\n",
    "\n",
    "        if self.crop_right:\n",
    "            xW = Lambda(self._crop_right, name='h_crop_right_'+str(layer_idx))(xW)\n",
    "\n",
    "        if self.v_map is not None:\n",
    "            #xW = merge([xW, self.v_map], mode='sum', name='h_merge_v_'+str(layer_idx))\n",
    "            xW = add([xW, self.v_map], name='h_merge_v_'+str(layer_idx))\n",
    "        \n",
    "        if self.h is not None:\n",
    "            hV = Dense(output_dim=2*self.nb_filters, name=stack_tag+'_dense_latent_'+str(layer_idx))(self.h)\n",
    "            hV = Reshape((1, 1, 2*self.nb_filters), name=stack_tag+'_reshape_latent_'+str(layer_idx))(hV)\n",
    "            #xW = merge([xW, hV], mode=lambda x: x[0]+x[1])\n",
    "            xW = Lambda(lambda x: x[0]+x[1], name=stack_tag+'_merge_latent_'+str(layer_idx))([xW,hV])\n",
    "\n",
    "        xW_f = Lambda(lambda x: x[:,:,:,:self.nb_filters], name=stack_tag+'_Wf_'+str(layer_idx))(xW)\n",
    "        xW_g = Lambda(lambda x: x[:,:,:,self.nb_filters:], name=stack_tag+'_Wg_'+str(layer_idx))(xW)\n",
    "\n",
    "        xW_f = Lambda(lambda x: K.tanh(x), name=stack_tag+'_tanh_'+str(layer_idx))(xW_f)\n",
    "        xW_g = Lambda(lambda x: K.sigmoid(x), name=stack_tag+'_sigmoid_'+str(layer_idx))(xW_g)\n",
    "\n",
    "        #res = merge([xW_f, xW_g], mode='mul', name=stack_tag+'_merge_gate_'+str(layer_idx))\n",
    "        res = multiply([xW_f, xW_g], name=stack_tag+'_merge_gate_'+str(layer_idx))\n",
    "        #print(type(res), K.int_shape(res), hasattr(res, '_keras_history'))\n",
    "        return res\n",
    "\n",
    "#############################################################################################################\n",
    "\n",
    "class PixelCNN(object):\n",
    "    ''' Keras implementation of (conditional) Gated PixelCNN model '''\n",
    "    def __init__(self, input_size, nb_channels=3, conditional=False, latent_dim=10,\n",
    "        nb_pixelcnn_layers=13, nb_filters=128, filter_size_1st=(7,7), filter_size=(3,3),\n",
    "        optimizer='adadelta', es_patience=100, save_root='/tmp/pixelcnn', save_best_only=False,\n",
    "        **kwargs):\n",
    "        '''\n",
    "        Args:\n",
    "            input_size ((int,int))      : (height, width) pixels of input images\n",
    "            nb_channels (int)           : Number of channels for input images. (1 for grayscale images, 3                                               for color images)\n",
    "            conditional (bool)          : if True, use latent vector to model the conditional distribution p                                            (x|h) (default:False)\n",
    "            latent_dim (int)            : (if conditional==True,) Dimensions for latent vector.\n",
    "            nb_pixelcnn_layers (int)    : Number of layers (except last two ReLu layers). (default:13)\n",
    "            nb_filters (int)            : Number of filters (feature maps) for each layer. (default:128)\n",
    "            filter_size_1st ((int, int)): Kernel size for the first layer. (default: (7,7))\n",
    "            filter_size ((int, int))    : Kernel size for the subsequent layers. (default: (3,3))\n",
    "            optimizer (str)             : SGD optimizer (default: 'adadelta')\n",
    "            es_patience (int)           : Number of epochs with no improvement after which training will be                                             stopped (EarlyStopping)\n",
    "            save_root (str)             : Root directory to which {trained model file, parameter.txt,                                                   tensorboard log file} are saved\n",
    "            save_best_only (bool)       : if True, the latest best model will not be overwritten (default:                                              False)\n",
    "        '''\n",
    "        #K.set_image_dim_ordering('tf')\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.conditional = conditional\n",
    "        self.latent_dim = latent_dim\n",
    "        self.nb_pixelcnn_layers = nb_pixelcnn_layers\n",
    "        self.nb_filters = nb_filters\n",
    "        self.filter_size_1st = filter_size_1st\n",
    "        self.filter_size = filter_size\n",
    "        self.nb_channels = nb_channels\n",
    "        if self.nb_channels == 1:\n",
    "            self.loss = 'binary_crossentropy'\n",
    "        elif self.nb_channels == 3:\n",
    "            self.loss = 'categorical_crossentropy'\n",
    "        self.optimizer = optimizer\n",
    "        self.es_patience = es_patience\n",
    "        self.save_best_only = save_best_only\n",
    "\n",
    "        tensorboard_dir = os.path.join(save_root, 'pixelcnn-tensorboard')\n",
    "        checkpoint_path = os.path.join(save_root, 'pixelcnn-weights.{epoch:02d}-{val_loss:.4f}.hdf5')\n",
    "        self.tensorboard = TensorBoard(log_dir=tensorboard_dir)\n",
    "        ### \"save_weights_only=False\" causes error when exporting model architecture. (json or yaml)\n",
    "        self.checkpointer = ModelCheckpoint(filepath=checkpoint_path, verbose=1,\n",
    "                            save_weights_only=True, save_best_only=save_best_only)\n",
    "        self.earlystopping = EarlyStopping(monitor='val_loss', patience=es_patience, verbose=0, mode='auto')\n",
    "    \n",
    "\n",
    "    def _masked_conv(self, x, filter_size, stack_name, layer_idx, mask_type='B'):\n",
    "        if stack_name == 'vertical':\n",
    "            res = ZeroPadding2D(\n",
    "                padding=((filter_size[0]//2, 0), (filter_size[1]//2, filter_size[1]//2)),\n",
    "                name='v_pad_'+str(layer_idx))(x)\n",
    "            res = Conv2D(2*self.nb_filters, filter_size[0]//2+1, filter_size[1],\n",
    "                padding='valid', name='v_conv_'+str(layer_idx))(res)\n",
    "\n",
    "        elif stack_name == 'horizontal':\n",
    "            res = ZeroPadding2D(padding=((0, 0), (filter_size[1]//2, 0)), name='h_pad_'+str(layer_idx))(x)\n",
    "            if mask_type == 'A':\n",
    "                res = Conv2D(2*self.nb_filters, 1, filter_size[1]//2,\n",
    "                    padding='valid', name='h_conv_'+str(layer_idx))(res)\n",
    "            else:\n",
    "                res = Conv2D(2*self.nb_filters, 1, filter_size[1]//2+1,\n",
    "                    padding='valid', name='h_conv_'+str(layer_idx))(res)\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _shift_down(x):\n",
    "        x_shape = K.int_shape(x)\n",
    "        x = ZeroPadding2D(padding=((1,0),(0,0)))(x)\n",
    "        x = Lambda(lambda x: x[:,:x_shape[1],:,:])(x)\n",
    "        return x\n",
    "\n",
    "    def _feed_v_map(self, x, layer_idx):\n",
    "        ### shifting down feature maps\n",
    "        x = Lambda(self._shift_down, name='v_shift_down'+str(layer_idx))(x)\n",
    "        x = Conv2D(2*self.nb_filters, 1, 1, padding='valid', name='v_1x1_conv_'+str(layer_idx))(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def _build_layers(self, x, h=None):\n",
    "        ''' Whole architecture of (conditional) Gated PixelCNN model '''\n",
    "        # set latent vector\n",
    "        self.h = h\n",
    "\n",
    "        # first PixelCNN layer\n",
    "        ### (kxk) masked convolution can be achieved by (k//2+1, k) convolution and padding.\n",
    "        v_masked_map = self._masked_conv(x, self.filter_size_1st, 'vertical', 0)\n",
    "        ### (i-1)-th vertical activation maps into the i-th hirizontal stack.\n",
    "        # (if i==0, vertical activation maps == input images)\n",
    "        v_feed_map = self._feed_v_map(v_masked_map, 0)\n",
    "        v_stack_out = GatedCNN(self.nb_filters, 'vertical', v_map=None, h=self.h)(v_masked_map, 0)\n",
    "        ### (1xk) masked convolution can be achieved by (1 x k//2+1) convolution and padding.\n",
    "        h_masked_map = self._masked_conv(x, self.filter_size_1st, 'horizontal', 0, 'A')\n",
    "        ### Mask A is applied to the first layer (achieved by cropping), and v_feed_maps are merged. \n",
    "        h_stack_out = GatedCNN(self.nb_filters, 'horizontal', v_map=v_feed_map,\n",
    "            h=self.h, crop_right=True)(h_masked_map, 0)\n",
    "        ### not residual connection in the first layer.\n",
    "        h_stack_out = Conv2D(self.nb_filters, 1, 1, padding='valid',\n",
    "            name='h_1x1_conv_0')(h_stack_out)\n",
    "\n",
    "        # subsequent PixelCNN layers\n",
    "        for i in range(1, self.nb_pixelcnn_layers):\n",
    "            v_masked_map = self._masked_conv(v_stack_out, self.filter_size, 'vertical', i)\n",
    "            v_feed_map = self._feed_v_map(v_masked_map, i)\n",
    "            v_stack_out = GatedCNN(self.nb_filters, 'vertical', v_map=None, h=self.h)(v_masked_map, i)\n",
    "            ### for residual connection\n",
    "            h_stack_out_prev = h_stack_out\n",
    "            h_masked_map = self._masked_conv(h_stack_out, self.filter_size, 'horizontal', i)\n",
    "            ### Mask B is applied to the subsequent layers.\n",
    "            h_stack_out = GatedCNN(self.nb_filters, 'horizontal', v_map=v_feed_map,\n",
    "                h=self.h)(h_masked_map, i)\n",
    "            h_stack_out = Conv2D(self.nb_filters, 1, 1, padding='valid',\n",
    "                name='h_1x1_conv_'+str(i))(h_stack_out)\n",
    "            ### residual connection\n",
    "            #h_stack_out = merge([h_stack_out, h_stack_out_prev], mode='sum', name='h_residual_'+str(i))\n",
    "            h_stack_out = add([h_stack_out, h_stack_out_prev], name='h_residual_'+str(i))\n",
    "\n",
    "        # (1x1) convolution layers (2 layers)\n",
    "        for i in range(2):\n",
    "            h_stack_out = Conv2D(self.nb_filters, 1, 1, activation='relu',\n",
    "                padding='valid', name='penultimate_convs'+str(i))(h_stack_out)\n",
    "        \n",
    "        # Softmax layer (256-way for each RGB color (natural image) or sigmoid for each pixel (MNIST))\n",
    "        if self.nb_channels == 1:\n",
    "            res = Conv2D(1, 1, 1, activation='sigmoid', padding='valid')(h_stack_out)\n",
    "            #res = Reshape((self.input_size[0]*self.input_size[1], 1))(res)\n",
    "            return res\n",
    "        elif self.nb_channels == 3:\n",
    "            ### 256-way * 3(channels) = 768\n",
    "            res = Conv2D(768, nb_row=1, nb_col=1, padding='valid')(h_stack_out)\n",
    "            res = Reshape((self.input_size[0] * self.input_size[1] * 3, 256))(res)\n",
    "            return Activation('softmax')(res)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "        ''' build conditional PixelCNN model '''\n",
    "        if self.nb_channels == 1:\n",
    "            input_img = Input(shape=(self.input_size[0], self.input_size[1], 1), name='grayscale_image')\n",
    "        elif self.nb_channels == 3:\n",
    "            input_img = Input(shape=(self.input_size[0], self.input_size[1], 3), name='color_image')\n",
    "\n",
    "        if self.conditional:\n",
    "            latent_vector = Input(shape=(self.latent_dim,), name='latent_vector')\n",
    "            predicted = self._build_layers(input_img, latent_vector)\n",
    "            self.model = Model(input=[input_img, latent_vector], output=predicted)\n",
    "        else:\n",
    "            predicted = self._build_layers(input_img)\n",
    "            self.model = Model(input_img, predicted)\n",
    "\n",
    "        self.model.compile(optimizer=self.optimizer, loss=self.loss)\n",
    "    \n",
    "\n",
    "    def fit(self, x, y, batch_size, nb_epoch, validation_data=None, shuffle=True):\n",
    "        ''' call fit function\n",
    "        Args:\n",
    "            x (np.ndarray or [np.ndarray, np.ndarray])  : Input data for training\n",
    "            y (np.ndarray)                              : Label data for training \n",
    "            samples_per_epoch (int)                     : Number of data for each epoch\n",
    "            nb_epoch (int)                              : Number of epoches\n",
    "            validation_data ((np.ndarray, np.ndarray))  : Validation data\n",
    "            nb_val_samples (int)                        : Number of data yielded by validation generator\n",
    "            shuffle (bool)                              : if True, shuffled randomly\n",
    "        '''\n",
    "        self.model.fit(x=x, y=y, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "            callbacks=[self.tensorboard, self.checkpointer, self.earlystopping],\n",
    "            validation_data=validation_data, shuffle=shuffle)\n",
    "\n",
    "    def fit_generator(self, train_generator, samples_per_epoch, nb_epoch,\n",
    "        validation_data=None, nb_val_samples=10000):\n",
    "        ''' call fit_generator function\n",
    "        Args:\n",
    "            train_generator (object)        : image generator built by \"build_generator\" function\n",
    "            samples_per_epoch (int)         : Number of data for each epoch\n",
    "            nb_epoch (int)                  : Number of epoches\n",
    "            validation_data (object/array)  : generator object or numpy.ndarray\n",
    "            nb_val_samples (int)            : Number of data yielded by validation generator\n",
    "        '''\n",
    "        self.model.fit_generator(generator=train_generator, samples_per_epoch=samples_per_epoch,\n",
    "            nb_epoch=nb_epoch, callbacks=[self.tensorboard, self.checkpointer, self.earlystopping],\n",
    "            validation_data=validation_data, nb_val_samples=nb_val_samples)\n",
    "\n",
    "\n",
    "    def load_model(self, checkpoint_file):\n",
    "        ''' restore model from checkpoint file (.hdf5) '''\n",
    "        self.model = load_model(checkpoint_file)\n",
    "\n",
    "    def export_to_json(self, save_root):\n",
    "        ''' export model architecture config to json file '''\n",
    "        with open(os.path.join(save_root, 'pixelcnn_model.json'), 'w') as f:\n",
    "            f.write(self.model.to_json())\n",
    "\n",
    "    def export_to_yaml(self, save_root):\n",
    "        ''' export model architecture config to yaml file '''\n",
    "        with open(os.path.join(save_root, 'pixelcnn_model.yml'), 'w') as f:\n",
    "            f.write(self.model.to_yaml())\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def predict(self, x, batch_size):\n",
    "        ''' generate image pixel by pixel\n",
    "        Args:\n",
    "            x or [x,h] (x,h: numpy.ndarray : x = input image, h = latent vector\n",
    "        Returns:\n",
    "            predict (numpy.ndarray)        : generated image\n",
    "        '''\n",
    "        return self.model.predict(x, batch_size)\n",
    "\n",
    "\n",
    "    def print_train_parameters(self, save_root):\n",
    "        ''' print parameter list file '''\n",
    "        print('\\n########## PixelCNN options ##########')\n",
    "        print('input_size\\t: %s' % (self.input_size,))\n",
    "        print('nb_pixelcnn_layers: %s' % self.nb_pixelcnn_layers)\n",
    "        print('nb_filters\\t: %s' % self.nb_filters)\n",
    "        print('filter_size_1st\\t: %s' % (self.filter_size_1st,))\n",
    "        print('filter_size\\t: %s' % (self.filter_size,))\n",
    "        print('conditional\\t: %s' % self.conditional)\n",
    "        print('nb_channels\\t: %s' % self.nb_channels)\n",
    "        print('optimizer\\t: %s' % self.optimizer)\n",
    "        print('loss\\t\\t: %s' % self.loss)\n",
    "        print('es_patience\\t: %s' % self.es_patience)\n",
    "        print('save_root\\t: %s' % save_root)\n",
    "        print('save_best_only\\t: %s' % self.save_best_only)\n",
    "        print('\\n')\n",
    "\n",
    "    def export_train_parameters(self, save_root):\n",
    "        ''' export parameter list file '''\n",
    "        with open(os.path.join(save_root, 'parameters.txt'), 'w') as txt_file:\n",
    "            txt_file.write('########## PixelCNN options ##########\\n')\n",
    "            txt_file.write('input_size\\t: %s\\n' % (self.input_size,))\n",
    "            txt_file.write('nb_pixelcnn_layers: %s\\n' % self.nb_pixelcnn_layers)\n",
    "            txt_file.write('nb_filters\\t: %s\\n' % self.nb_filters)\n",
    "            txt_file.write('filter_size_1st\\t: %s\\n' % (self.filter_size_1st,))\n",
    "            txt_file.write('filter_size\\t: %s\\n' % (self.filter_size,))\n",
    "            txt_file.write('conditional\\t: %s\\n' % self.conditional)\n",
    "            txt_file.write('nb_channels\\t: %s\\n' % self.nb_channels)\n",
    "            txt_file.write('optimizer\\t: %s\\n' % self.optimizer)\n",
    "            txt_file.write('loss\\t\\t: %s\\n' % self.loss)\n",
    "            txt_file.write('es_patience\\t: %s\\n' % self.es_patience)\n",
    "            txt_file.write('save_root\\t: %s\\n' % save_root)\n",
    "            txt_file.write('save_best_only\\t: %s\\n' % self.save_best_only)\n",
    "            txt_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage.io import imread\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Utils(object):\n",
    "\n",
    "    @staticmethod\n",
    "    def image2kerasarray(img):\n",
    "        ''' reshape image array \n",
    "        Args:\n",
    "            img (numpy.ndarray)     : common image array ((nb_images,)height,width(,3))\n",
    "        Returns:\n",
    "            array (numpy.ndarray)   : keras array ((nb_images,)height,width,channels)\n",
    "        '''\n",
    "        array = img.astype('float32') / 255.\n",
    "        if array.shape[-1] != 3: ### (num_images, height, width) ###\n",
    "            array = np.expand_dims(array, axis=-1)\n",
    "\n",
    "        return array\n",
    "\n",
    "    @staticmethod\n",
    "    def image2labelmap(img):\n",
    "        ''' convert color image to label map\n",
    "        Args:\n",
    "            img (numpy.ndarray)     : common color image array (height,width,3)\n",
    "        Returns:\n",
    "            label_map (np.ndarray)\t: label map (height*width*3,256)\n",
    "        '''\n",
    "        height, width, _  = img.shape\n",
    "        label_map = np.zeros([height*width*3, 256])\n",
    "        for h in range(height):\n",
    "            for w in range(width):\n",
    "                for c in range(3):\n",
    "                    label_map[3*width*h + 3*w + c, img[h][w][c]] = 1\n",
    "\n",
    "        return label_map\n",
    "\n",
    "    @classmethod\n",
    "    def load_mnist_datasets(cls, conditional=False):\n",
    "        ''' load mnist dataset\n",
    "        Args:\n",
    "            conditional (bool)\t: if True, return image arrays and class label vectors. if False, return                                        only image arrays.\n",
    "        Returns:\n",
    "            ([X_train, h_train], Y_train), ([X_validation, h_validation], Y_validation)\t: if conditional ==                                                                                                         True\n",
    "            (X_train, Y_train), (X_validation, Y_validation)\t\t\t\t\t\t\t: if conditional ==                                                                                                         False\n",
    "        *** Loading {'cifar10', 'cifar100'} dataset causes MemoryError due to the softmax layer. ***\n",
    "        '''\n",
    "        from keras.datasets import mnist\n",
    "        (X_train, h_train), (X_validation, h_validation) = mnist.load_data()\n",
    "        nb_classes = 10\n",
    "\n",
    "        from keras.utils import np_utils\n",
    "\n",
    "        X_train = cls.image2kerasarray(X_train)\n",
    "        X_validation = cls.image2kerasarray(X_validation)\n",
    "\n",
    "        ### In case single channel, Y = X ###\n",
    "        X_train = cls.binarize_array(X_train)\n",
    "        X_validation = cls.binarize_array(X_validation)\n",
    "        Y_train = X_train\n",
    "        Y_validation = X_validation\n",
    "\n",
    "        ### If conditional == True, use class labels as latent vector ###\n",
    "        if conditional:\n",
    "            h_train = np_utils.to_categorical(h_train, nb_classes)\n",
    "            h_validation = np_utils.to_categorical(h_validation, nb_classes)\n",
    "\n",
    "\n",
    "        if conditional:\n",
    "            return (([X_train, h_train], Y_train), ([X_validation, h_validation], Y_validation))\n",
    "        else:\n",
    "            return ((X_train, Y_train), (X_validation, Y_validation))\n",
    "\n",
    "    @classmethod\n",
    "    def build_data_generator_from_keras_datasets(cls, dataset_name, X, H=None, batch_size=100):\n",
    "        ''' kerasarray generator without keras ImageDataGenerator\n",
    "            Args:\n",
    "                dataset_name (str)\t: {'mnist', 'cifar10', 'cifar100'}\n",
    "                X (numpy.ndarray)\t: Image arrays. (nb_images, height, width (, 3))\n",
    "                H (numpy.ndarray)\t: Latent vectors (nb_images, nb_classes)\n",
    "                batch_size (int)\t: minibatch size that generator yields at once\n",
    "        '''\n",
    "        from keras.utils import np_utils\n",
    "\n",
    "        if dataset_name == 'mnist':\n",
    "            target_size = (28, 28)\n",
    "            nb_classes = 10\n",
    "        elif dataset_name == 'cifar10':\n",
    "            target_size = (32, 32)\n",
    "            nb_classes = 10\n",
    "        elif dataset_name == 'cifar100':\n",
    "            target_size = (32, 32)\n",
    "            nb_classes = 100\n",
    "\n",
    "        while 1:\n",
    "            if dataset_name == 'mnist':\n",
    "                x = np.zeros((batch_size, target_size[0], target_size[1], 1))\n",
    "                y = np.zeros((batch_size, target_size[0], target_size[1], 1))\n",
    "            else:\n",
    "                x = np.zeros((batch_size, target_size[0], target_size[1], 3))\n",
    "                y = np.zeros((batch_size, target_size[0]*target_size[1]*3, 256))\n",
    "            if H is not None:\n",
    "                h = np.zeros((batch_size, nb_classes))\n",
    "                H = np_utils.to_categorical(H, nb_classes)\n",
    "\n",
    "            batch_idx = 0\n",
    "            shuffled_index = list(range(len(X)))\n",
    "            random.shuffle(shuffled_index)\n",
    "\n",
    "            for i in shuffled_index:\n",
    "                if dataset_name == 'mnist':\n",
    "                    binarized_X = cls.binarize_array(cls.image2kerasarray(X[i]))\n",
    "                    x[batch_idx % batch_size] = binarized_X\n",
    "                    y[batch_idx % batch_size] = binarized_X\n",
    "                else:\n",
    "                    x[batch_idx % batch_size] = cls.image2kerasarray(X[i])\n",
    "                    y[batch_idx % batch_size] = cls.image2labelmap(X[i])\n",
    "                if h is not None:\n",
    "                    h[batch_idx % batch_size] = H[i]\n",
    "                batch_idx += 1\n",
    "                if (batch_idx % batch_size) == 0:\n",
    "                    if h is not None:\n",
    "                        yield ([x, h], y)\n",
    "                    else:\n",
    "                        yield (x, y)\n",
    "\n",
    "    @staticmethod\n",
    "    def read_image(path):\n",
    "        ''' read image from filepath\n",
    "        Args:\n",
    "            path (str)              : filepath (/path/to/img.jpg)\n",
    "        Returns:\n",
    "            image (numpy.ndarray)   : np.array of shepe (height, width, channels)\n",
    "        '''\n",
    "        img = imread(path)\n",
    "        return img\n",
    "\n",
    "    @classmethod\n",
    "    def build_data_generator_from_directory(cls, target_size, data_paths, batch_size=100):\n",
    "        ''' kerasarray generator without keras ImageDataGenerator\n",
    "            Args:\n",
    "                target_size (int,int)       : (height, width) pixels of image\n",
    "                data_paths (list(str))      : [\"/path/to/image001.jpg\", \"/path/to/image002.jpg\", ...]\n",
    "                batch_size (int)            : minibatch size that generator yields at once\n",
    "        '''\n",
    "        while 1:\n",
    "            x = np.zeros((batch_size, target_size[0], target_size[1], 3))\n",
    "            y = np.zeros((batch_size, target_size[0]*target_size[1]*3, 256))\n",
    "            batch_idx = 0\n",
    "            shuffled_index = list(range(len(data_paths)))\n",
    "            random.shuffle(shuffled_index)\n",
    "\n",
    "            for i in shuffled_index:\n",
    "                x[batch_idx % batch_size] = cls.image2kerasarray(cls.read_image(data_paths[i]))\n",
    "                y[batch_idx % batch_size] = cls.image2labelmap(cls.read_image(data_paths[i]))\n",
    "                batch_idx += 1\n",
    "                if (batch_idx % batch_size) == 0:\n",
    "                    yield (x, y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def binarize_val(pred):\n",
    "       ''' probability -> binarized value '''\n",
    "       return (np.random.uniform(size=1) < pred).astype(np.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def binarize_array(array):\n",
    "        ''' scaled image (value range:0-1) -> binarized array '''\n",
    "        return (np.random.uniform(size=array.shape) < array).astype(np.float32)\n",
    "    \n",
    "    @staticmethod\n",
    "    def sample(preds, temperature=1.0):\n",
    "        # helper function to sample an index from a probability array\n",
    "        # copied from https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
    "        preds = np.asarray(preds).astype('float32')\n",
    "        preds = np.log(preds) / temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        probas = np.random.multinomial(1, preds, 1)\n",
    "\n",
    "        return np.argmax(probas).astype('float32') / 255.\n",
    "\n",
    "    @staticmethod\n",
    "    def save_generated_image(img, filename=\"img.jpg\", save_path='/tmp/pixelcnn/results'):\n",
    "        ''' save predicted image\n",
    "        Args:\n",
    "            img (numpy.array)       : Image array\n",
    "            filename (str)          : Save image to save_path/filename\n",
    "            save_root (str)         : Save image to save_path/filename\n",
    "        '''\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "\n",
    "        fig = plt.figure(figsize=(15, 15))\n",
    "        ax = plt.subplot(1, 1, 1)\n",
    "        ax.imshow(img)\n",
    "        fig.savefig(os.path.join(save_path, filename))\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def save_generated_images(imgs, cols, filename='img.jpg', save_path='/tmp/pixelcnn/results'):\n",
    "        ''' save predicted images\n",
    "        Args:\n",
    "            imgs (numpy.array)\t\t: Image arrays\n",
    "            cols (int)\t\t\t\t: number of columns for visualizing images\n",
    "            filename (str)\t\t\t: Save image to save_path/filename\n",
    "            save_root (str)\t\t\t: Save image to save_path/filename\n",
    "        '''\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "\n",
    "        fig = plt.figure()\n",
    "        rows = len(imgs) // cols + 1\n",
    "\n",
    "        for j in range(len(imgs)):\n",
    "            ax = fig.add_subplot(cols, rows, j+1)\n",
    "            ax.matshow(imgs[j], cmap=matplotlib.cm.binary)\n",
    "            plt.xticks(np.array([]))\n",
    "            plt.yticks(np.array([]))\n",
    "        plt.tight_layout()\n",
    "\n",
    "        fig.savefig(os.path.join(save_path, filename))\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Operands could not be broadcast together with shapes (11, 11, 256) (5, 5, 256)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-4fc737aacd06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpixelcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPixelCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpixelcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpixelcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-e3383eae71be>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_vector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-e3383eae71be>\u001b[0m in \u001b[0;36m_build_layers\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mh_masked_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_masked_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_size_1st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'horizontal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'A'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m### Mask A is applied to the first layer (achieved by cropping), and v_feed_maps are merged.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         h_stack_out = GatedCNN(self.nb_filters, 'horizontal', v_map=v_feed_map,\n\u001b[0m\u001b[1;32m    155\u001b[0m             h=self.h, crop_right=True)(h_masked_map, 0)\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m### not residual connection in the first layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-e3383eae71be>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, xW, layer_idx)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m#xW = merge([xW, self.v_map], mode='sum', name='h_merge_v_'+str(layer_idx))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mxW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_map\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'h_merge_v_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(inputs, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m   \"\"\"\n\u001b[0;32m--> 767\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    110\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m       \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_elemwise_op_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0;31m# If the inputs have different ranks, we have to reshape them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# to make them broadcastable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.8/site-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36m_compute_elemwise_op_output_shape\u001b[0;34m(self, shape1, shape2)\u001b[0m\n\u001b[1;32m     81\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m           raise ValueError(\n\u001b[0m\u001b[1;32m     84\u001b[0m               \u001b[0;34m'Operands could not be broadcast '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m               'together with shapes ' + str(shape1) + ' ' + str(shape2))\n",
      "\u001b[0;31mValueError\u001b[0m: Operands could not be broadcast together with shapes (11, 11, 256) (5, 5, 256)"
     ]
    }
   ],
   "source": [
    "pixelcnn = PixelCNN((32, 32))\n",
    "pixelcnn.build_model()\n",
    "pixelcnn.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}